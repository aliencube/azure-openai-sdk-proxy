@using AzureOpenAIProxy.PlaygroundApp.Clients
@using AzureOpenAIProxy.PlaygroundApp.Models

@inject IOpenAIApiClient Api

<FluentStack Id="@Id" Style="width: 100%; height: 100%;" Orientation="Orientation.Vertical" VerticalAlignment="VerticalAlignment.Bottom">
    <ChatHistoryComponent Id="chat-history" Messages="messages" />
    <ChatPromptComponent Id="chat-prompt" OnPromptSent="SendPrompt" OnChatCleared="ClearMessage" />
</FluentStack>

@code {
    private string? apiKey = "abcdef";
    private string? deploymentName = "model-gpt35turbo16k-0613";
    private int? maxTokens = 4096;
    private float? temperature = 0.7f;
    private string? systemPrompt = "You are an AI assistant that helps people find information.";

    private List<ChatMessage>? messages;

    [Parameter]
    public string? Id { get; set; }

    protected override async Task OnInitializedAsync()
    {
        this.messages = [];

        await Task.CompletedTask;
    }

    private async Task SendPrompt(string prompt)
    {
        this.messages!.Add(new ChatMessage() { Role = MessageRole.User, Message = prompt });
        var options = new OpenAIApiClientOptions()
            {
                ApiKey = apiKey,
                DeploymentName = deploymentName,
                MaxTokens = maxTokens,
                Temperature = temperature,
                SystemPrompt = systemPrompt,
                UserPrompt = prompt,
            };

        var result = await Api.CompleteChatAsync(options);
        this.messages!.Add(new ChatMessage() { Role = MessageRole.Assistant, Message = result });
    }

    private async Task ClearMessage()
    {
        this.messages!.Clear();

        await Task.CompletedTask;
    }
}